{
 "cells": [
  {
   "cell_type": "raw",
   "id": "170e8f31",
   "metadata": {},
   "source": [
    "创造分支createBranch（）（递归函数）\n",
    "检测数据集中的每一个子项是否是同一分类：\n",
    "    if so return 类标签\n",
    "    else\n",
    "        寻找划分数据集的最好特征\n",
    "        划分数据集\n",
    "        创建分支节点\n",
    "            for 每个划分的子集\n",
    "                调用函数createBranch并增加返回值到分支节点中\n",
    "            return 分支节点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42bfaf1",
   "metadata": {},
   "source": [
    "**计算给定数据集的信息熵** \\\n",
    "$$ H = -\\sum^n_{i=1}p(x_i)log_2p(x_i)     \\tag{香农熵} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ac31f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from math import log\n",
    "import numpy as np\n",
    "\n",
    "def calcShannoEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLable = featVec[-1]\n",
    "        if currentLable not in labelCounts.keys():\n",
    "            labelCounts[currentLable] = 0\n",
    "        labelCounts[currentLable] += 1\n",
    "    shannoEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannoEnt -= prob * log(prob, 2)\n",
    "    return shannoEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d11e0",
   "metadata": {},
   "source": [
    "以上代码是将每个类别出现的次数，以k-v的方式保存在字典，并按照公式计算出熵值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0a48ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 1, 'y'], [1, 1, 'y'], [1, 0, 'n'], [0, 1, 'n'], [0, 1, 'n']],\n",
       " ['no surfaceing', 'flippers'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "def createDateSet():\n",
    "    dataSet = [[1,1,'y'],[1,1,'y'],[1,0,'n'],[0,1,'n'],[0,1,'n']]\n",
    "    labels = ['no surfaceing', 'flippers']\n",
    "    return dataSet, labels\n",
    "\n",
    "mydata,mylabels=createDateSet()\n",
    "mydata,mylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92182a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannoEnt(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c469f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 1, 'maybe'], [1, 1, 'y'], [1, 0, 'n'], [0, 1, 'n'], [0, 1, 'n']],\n",
       " 1.3709505944546687)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[0][-1]='maybe'\n",
    "mydata,calcShannoEnt(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad1134",
   "metadata": {},
   "source": [
    "可以看到 在增加更多的分类后，熵值增加了，也就是数据的混乱程度增加了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf2b2d",
   "metadata": {},
   "source": [
    "得到熵值以后，我们就可以按照最大信息增益来划分数据集了，再此之前补充两个知识，extend 与 append的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4cd8684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, [4, 5, 6]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3];b=[4,5,6]\n",
    "a.append(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cbd762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "a.extend(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cd32f",
   "metadata": {},
   "source": [
    "当我们按照某个特征划分数据集的时候，就是将所有的，符合条件的元素都抽取出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2b924dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet1 = []\n",
    "    retDataSet2 = []\n",
    "    for featVec in dataSet:\n",
    "        if float(featVec[axis]) >= value:\n",
    "            retDataSet1.append(featVec)\n",
    "        if float(featVec[axis]) < value:\n",
    "            retDataSet2.append(featVec)\n",
    "    return retDataSet1,retDataSet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5297b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbde6447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 'maybe'], [1, 'y'], [0, 'n']], [[1, 'n'], [1, 'n']])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "data1=splitDataSet(mydata,0,1)\n",
    "data2=splitDataSet(mydata,0,0)\n",
    "data1,data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c7d40",
   "metadata": {},
   "source": [
    "现在已经找到按指定特征划分数据集的方法了，下一步就是寻找一种最好的划分数据集发的方式\\\n",
    "最好的数据集划分方式要使得划分后的信息增益最大（ID3）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f446bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0])-1 # -1的原因是减去一列的分类，获取特征的类数\n",
    "    baseEnt = calcShannoEnt(dataSet) # 计算最开始的熵值\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeat = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [a[i] for a in dataSet] # 把第i类特征的所有可能取值放入featList\n",
    "        uniqueVals = set(featList) # set集合去重\n",
    "        newEnt = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet,i,value) # 划分数据集\n",
    "            prob = len(subDataSet)/float(len(dataSet)) # 计算概率\n",
    "            newEnt += prob * calcShannoEnt(subDataSet) # 计算新熵值\n",
    "        infoGain = baseEnt - newEnt # 计算信息增益\n",
    "        if(infoGain > bestInfoGain): #记录最佳信息增益的特征\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeat = i\n",
    "    return bestFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21e1871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatSplit(mydata) # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b261f",
   "metadata": {},
   "source": [
    "**递归构建决策树**\n",
    "\n",
    "递归结束的条件\n",
    "- 遍历完所有数据集属性\n",
    "- 每个分支下的所有实例都具有相同的分类\n",
    "\n",
    "但是在一些情况下，用完所以的属性，但类标签仍然不是唯一，这个时候采用多数表决方式决定该节点的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fea80c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityCnt(classList): #类似于knn决策函数\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4193e6ac",
   "metadata": {},
   "source": [
    "**现在可以开始构建决策树了**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81b28c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    classList = [a[-1] for a in dataSet] # 获取所有类标签\n",
    "    if classList.count(classList[0]) == len(classList): \n",
    "        return classList[0]  # 如果类别完全相同，停止继续划分\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList) # 如果遍历完所有特征，则返回出现类别最多的类别\n",
    "    bestFeatIndex = chooseBestFeatSplit(dataSet) # 选择最好的特征进行划分\n",
    "    bestFeatLabel = labels[bestFeatIndex]\n",
    "    mytree = {bestFeatLabel:{}}\n",
    "    del(labels[bestFeatIndex]) # 删除已使用特征\n",
    "    featValues = [a[bestFeatIndex] for a in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:] # 参数按引用方式传递，直接传会改变lables的值，故复制一份\n",
    "        mytree[bestFeatLabel][value]=createTree(splitDataSet(dataSet,bestFeatIndex,value),subLabels) # 递归调用\n",
    "    return mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d481c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfaceing': {0: 'n', 1: {'flippers': {0: 'n', 1: 'y'}}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "mydata,mylabels=createDateSet()\n",
    "myTree= createTree(mydata,mylabels)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "42324a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 使用决策树执行分类\n",
    "def classify(inputTree,featLabels,testVec):\n",
    "    carLabel = 'error'\n",
    "    firstStr = list(inputTree.keys())[0] # 找到根节点\n",
    "    secondDict = inputTree[firstStr] # 获取子树\n",
    "    featIndex = featLabels.index(firstStr) # 找到划分数据集的特征在实际数据集中的位置（索引方式）\n",
    "    for key in secondDict.keys():\n",
    "        if float(testVec[featIndex]) >= float(key[1:]) and key[0] == '>' and type(secondDict[key]) == dict: \n",
    "             carLabel = classify(secondDict[key],featLabels,testVec)\n",
    "        elif float(testVec[featIndex]) < float(key[1:]) and key[0] == '<' and type(secondDict[key]) == dict: \n",
    "             carLabel = classify(secondDict[key],featLabels,testVec)\n",
    "        elif float(testVec[featIndex]) >= float(key[1:]) and key[0] == '>' and type(secondDict[key]) != dict: \n",
    "            carLabel=secondDict[key]\n",
    "        elif float(testVec[featIndex]) < float(key[1:]) and key[0] == '<' and type(secondDict[key]) != dict: \n",
    "            carLabel=secondDict[key]         \n",
    "    return carLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "152dc18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata,mylabels=createDateSet()\n",
    "classify(myTree,mylabels,[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b6c6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'no', 'normal', 'soft'],\n",
       " ['young', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['young', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['young', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'no', 'normal', 'soft'],\n",
       " ['pre', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['pre', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'yes', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读入数据\n",
    "fr=open('lenses.txt')\n",
    "lenses=[i.strip().split('\\t') for i in fr.readlines()]\n",
    "lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b640fdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tearRate': {'normal': {'astigmatic': {'no': {'age': {'presbyopic': {'prescript': {'hyper': 'soft',\n",
       "        'myope': 'no lenses'}},\n",
       "      'young': 'soft',\n",
       "      'pre': 'soft'}},\n",
       "    'yes': {'prescript': {'hyper': {'age': {'presbyopic': 'no lenses',\n",
       "        'young': 'hard',\n",
       "        'pre': 'no lenses'}},\n",
       "      'myope': 'hard'}}}},\n",
       "  'reduced': 'no lenses'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenseLables=['age','prescript','astigmatic','tearRate']\n",
    "lenseTree =createTree(lenses,lenseLables)\n",
    "lenseTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81650e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree_Fix(dataSet,labels):\n",
    "    classList = [a[-1] for a in dataSet] # 获取所有类标签\n",
    "    if len(dataSet)<=3 : return majorityCnt(classList)# 某样本数小于等于3不再分裂 直接多数表决\n",
    "    if classList.count(classList[0]) == len(classList): \n",
    "        return classList[0]  # 如果类别完全相同，停止继续划分\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList) # 如果遍历完所有特征，则返回出现类别最多的类别\n",
    "    bestFeatIndex = chooseBestFeatSplit(dataSet) # 选择最好的特征进行划分\n",
    "    bestFeatLabel = labels[bestFeatIndex]\n",
    "    mytree = {bestFeatLabel:{}}\n",
    "    del(labels[bestFeatIndex]) # 删除已使用特征\n",
    "    featValues = [a[bestFeatIndex] for a in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:] # 参数按引用方式传递，直接传会改变lables的值，故复制一份\n",
    "        mytree[bestFeatLabel][value]=createTree_Fix(splitDataSet(dataSet,bestFeatIndex,value),subLabels) # 递归调用\n",
    "    return mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ec5b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tearRate': {'reduced': 'no lenses',\n",
       "  'normal': {'astigmatic': {'yes': {'prescript': {'hyper': 'no lenses',\n",
       "      'myope': 'hard'}},\n",
       "    'no': {'age': {'presbyopic': 'no lenses',\n",
       "      'young': 'soft',\n",
       "      'pre': 'soft'}}}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenseLables=['age','prescript','astigmatic','tearRate']\n",
    "lenseTree_fix =createTree_Fix(lenses,lenseLables)\n",
    "lenseTree_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "797c1337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#读入数据\n",
    "mylist=[]\n",
    "fr=open('iris.data')\n",
    "irisSet=[i.strip().split(',') for i in fr.readlines()]\n",
    "np.random.shuffle(irisSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a298ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f442d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatSplit1(dataSet):\n",
    "    numFeatures = len(dataSet[0])-1 # -1的原因是减去一列的分类，获取特征的类数\n",
    "    baseEnt = calcShannoEnt(dataSet) # 计算最开始的熵值\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeat = -1\n",
    "    bestpoint = 0\n",
    "    splitpoint=0\n",
    "    for i in range(numFeatures):\n",
    "        featList = [float(a[i]) for a in dataSet] # 把第i类特征的所有可能取值放入featList\n",
    "        uniqueVals = set(featList)# set集合去重\n",
    "        uniqueVals = list(uniqueVals)\n",
    "        uniqueVals=sorted(uniqueVals)\n",
    "        bestpoint,InfoGain= chooseBestpoint(i,uniqueVals,dataSet)\n",
    "        if(InfoGain > bestInfoGain): #记录最佳信息增益的特征\n",
    "            bestInfoGain = InfoGain\n",
    "            bestFeat = i\n",
    "            splitpoint=bestpoint\n",
    "    return bestFeat,splitpoint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a543de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestpoint(axis,uniqueVals,dataSet):\n",
    "    baseEnt = calcShannoEnt(dataSet)# 计算最开始的熵值\n",
    "    bestInfoGain = 0.0\n",
    "    bestpoint = -1\n",
    "    uniqueVals=list(uniqueVals)\n",
    "    newsplitpoint=[(float(uniqueVals[i])+float(uniqueVals[i+1]))/2.0 for i in range(len(uniqueVals)-1)]\n",
    "    for value in newsplitpoint:\n",
    "            subDataSet1,subDataSet2 = splitDataSet(dataSet,axis,value) # 划分数据集\n",
    "            prob1 = len(subDataSet1)/float(len(dataSet)) # 计算概率\n",
    "            prob2 = len(subDataSet2)/float(len(dataSet)) \n",
    "            newEnt = prob1 * calcShannoEnt(subDataSet1)+prob2*calcShannoEnt(subDataSet2) # 计算新熵值\n",
    "            infoGain = baseEnt - newEnt # 计算信息增益\n",
    "            if(infoGain > bestInfoGain): #记录最佳信息增益的特征\n",
    "                bestInfoGain = infoGain\n",
    "                bestpoint = value \n",
    "    return bestpoint,bestInfoGain\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "898e75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree1(dataSet,labels):\n",
    "    classList = [a[-1] for a in dataSet] # 获取所有类标签\n",
    "    if classList.count(classList[0]) == len(classList): \n",
    "        return classList[0]  # 如果类别完全相同，停止继续划分\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList) # 如果遍历完所有特征，则返回出现类别最多的类别\n",
    "    bestFeatIndex,splitpoint = chooseBestFeatSplit1(dataSet) # 选择最好的特征进行划分\n",
    "    bestFeatLabel = labels[bestFeatIndex]\n",
    "    mytree = {bestFeatLabel:{}}\n",
    "    sp1,sp2=splitDataSet(dataSet,bestFeatIndex,float(splitpoint))\n",
    "    mytree[bestFeatLabel]['>{}'.format(splitpoint)]=createTree1(sp1,labels)\n",
    "    mytree[bestFeatLabel]['<{}'.format(splitpoint)]=createTree1(sp2,labels)\n",
    "                                                                       # 递归调用\n",
    "    return mytree\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f7be5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree2(dataSet,labels):\n",
    "    classList = [a[-1] for a in dataSet] # 获取所有类标签\n",
    "    if len(dataSet)<=4 : return majorityCnt(classList)\n",
    "    if classList.count(classList[0]) == len(classList): \n",
    "        return classList[0]  # 如果类别完全相同，停止继续划分\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList) # 如果遍历完所有特征，则返回出现类别最多的类别\n",
    "    bestFeatIndex,splitpoint = chooseBestFeatSplit1(dataSet) # 选择最好的特征进行划分\n",
    "    bestFeatLabel = labels[bestFeatIndex]\n",
    "    mytree = {bestFeatLabel:{}}\n",
    "    sp1,sp2=splitDataSet(dataSet,bestFeatIndex,float(splitpoint))\n",
    "    mytree[bestFeatLabel]['>{}'.format(splitpoint)]=createTree2(sp1,labels)\n",
    "    mytree[bestFeatLabel]['<{}'.format(splitpoint)]=createTree2(sp2,labels)\n",
    "                                                                       # 递归调用\n",
    "    return mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "df1aabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "irislabels=['sepal length','sepal width','petal length','petal width','class']\n",
    "trainSet=irisSet[50:]\n",
    "iristree=createTree1(trainSet,irislabels)\n",
    "isistree2=createTree2(trainSet,irislabels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ecfd065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet=irisSet[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c267b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1():\n",
    "    errorcnt=0.0\n",
    "    for i in testSet:\n",
    "        if classify(iristree,irislabels,i[:4]) != i[-1]:errorcnt += 1\n",
    "    print(errorcnt)\n",
    "    print(errorcnt/len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f6af9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun2():\n",
    "    errorcnt=0.0\n",
    "    for i in testSet:\n",
    "        if classify(isistree2,irislabels,i[:4]) != i[-1]:errorcnt += 1\n",
    "    print(errorcnt)\n",
    "    print(errorcnt/len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "31089bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "0.1\n",
      "3.0\n",
      "0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun1(),fun2() #90train 60test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "8adc9607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "0.04\n",
      "3.0\n",
      "0.06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun1(),fun2() #100train 50test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "2d300403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "0.04\n",
      "3.0\n",
      "0.06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun1(),fun2() #120train 30test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "5d5d6e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "0.06666666666666667\n",
      "2.0\n",
      "0.03333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读入数据\n",
    "mylist=[]\n",
    "fr=open('iris.data')\n",
    "irisSet=[i.strip().split(',') for i in fr.readlines()]\n",
    "np.random.shuffle(irisSet)\n",
    "irislabels=['sepal length','sepal width','petal length','petal width','class']\n",
    "trainSet=irisSet[60:]\n",
    "iristree=createTree1(trainSet,irislabels)\n",
    "iristree\n",
    "isistree2=createTree2(trainSet,irislabels)\n",
    "testSet=irisSet[:60]\n",
    "fun1(),fun2() #100train 50test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "4c78b09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'petal length': {'>2.45': {'petal width': {'>1.7000000000000002': {'petal length': {'>4.85': 'Iris-virginica',\n",
       "      '<4.85': {'sepal length': {'>5.95': 'Iris-virginica',\n",
       "        '<5.95': 'Iris-versicolor'}}}},\n",
       "    '<1.7000000000000002': {'petal length': {'>4.95': {'sepal length': {'>6.6': 'Iris-virginica',\n",
       "        '<6.6': {'sepal width': {'>2.45': 'Iris-versicolor',\n",
       "          '<2.45': 'Iris-virginica'}}}},\n",
       "      '<4.95': 'Iris-versicolor'}}}},\n",
       "  '<2.45': 'Iris-setosa'}}"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iristree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "ced2e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'petal length': {'>2.45': {'petal width': {'>1.7000000000000002': {'petal length': {'>4.85': 'Iris-virginica',\n",
       "      '<4.85': 'Iris-virginica'}},\n",
       "    '<1.7000000000000002': {'petal length': {'>4.95': 'Iris-virginica',\n",
       "      '<4.95': 'Iris-versicolor'}}}},\n",
       "  '<2.45': 'Iris-setosa'}}"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isistree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322ef7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
